# -*- coding: utf-8 -*-
"""skin-cancer-svm+rndom.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oHdBj2p51oyv3DyGrM8kE5Ye5GTrai4Y
"""

from sklearn import datasets

#Load dataset
cancer = datasets.load_breast_cancer()

# print the names of the 13 features
print("Features: ", cancer.feature_names)

# print the label type of cancer('malignant' 'benign')
print("Labels: ", cancer.target_names)

cancer.data.shape

print(cancer.data[0:5])

print(cancer.target)

from sklearn.model_selection import train_test_split

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,random_state=109) # 70% training and 30% test

from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

from sklearn import metrics

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_test, y_pred))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))

# Commented out IPython magic to ensure Python compatibility.
#Random forest
import pandas as pd
from pandas import Series,DataFrame

# numpy, matplotlib, seaborn
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('whitegrid')
# %matplotlib inline

# machine learning
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

from sklearn import model_selection
# random forest model creation
rfc = RandomForestClassifier()
rfc.fit(X_train,y_train)
# predictions
rfc_predict = rfc.predict(X_test)

from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report, confusion_matrix

rfc_cv_score = cross_val_score(rfc, cancer.data, cancer.target, cv=10, scoring='roc_auc')

# testing
print("=== Classification Report ===")
print(classification_report(y_test, rfc_predict))
print('\n')
print("Acuracy Score - Random Forest: ", rfc_cv_score.mean())

from sklearn.metrics import confusion_matrix
import itertools


mat = confusion_matrix(y_test, rfc_predict)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True)
plt.title('Confusion Matrix (Testing Dataset)')

plt.xlabel('true label')
plt.ylabel('predicted label');

# training
rfc2 = RandomForestClassifier(n_estimators=600, max_depth=300, max_features='sqrt')
rfc2.fit(X_train,y_train)
rfc_predict2 = rfc.predict(X_train)
rfc_cv_score2 = cross_val_score(rfc, cancer.data, cancer.target, cv=10, scoring='roc_auc')
print("=== Confusion Matrix ===")
print(confusion_matrix(y_train, rfc_predict2))
print('\n')
print("=== Classification Report ===")
print(classification_report(y_train, rfc_predict2))
print('\n')
print("Acuracy Score - Random Forest: ", rfc_cv_score2.mean())

from sklearn.metrics import confusion_matrix
import itertools

mat = confusion_matrix(y_train, rfc_predict2)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True)
plt.title('Confusion Matrix (Training Dataset)')

plt.xlabel('true label')
plt.ylabel('predicted label');

#feat_labels = ['z', 'fiberMag_u','modelMag_g','modelMag_r','modelMag_i','modelMag_z','psfMag_u','psfMag_g','psfMag_r','psfMag_i','psfMag_z']
#feat_labels = ['z', 'fiberMag_u','fiberMag_g','fiberMag_r','fiberMag_i','fiberMag_z','U-g','u-r','U-i','U-z','G-r','G-i','G-z','R-i','R-z','I-z','Lick_CN1','Lick_CN2','Lick_Ca4227','Lick_G4300','Lick_Fe4383','Lick_Ca4455',	'Lick_Fe4531','Lick_C4668','Lick_Hb',	'Lick_Fe5015',	'Lick_Mg1',	'Lick_Mg2',	'Lick_Mgb'	,'Lick_Fe5270',	'Lick_Fe5335',	'Lick_Fe5406'	,'Lick_Fe5709',	'Lick_Fe5782'	,'Lick_NaD'	,'Lick_TiO1'	,'Lick_TiO2'	,'B&H_CNB',	'B&H_H+K',	'B&H_CaI'	,'B&H_G'	,'B&H_Hb'	,'B&H_MgG'	,'B&H_MH'	,'B&H_FC',	'B&H_NaD',	'DTT_CaII8498',	'DTT_CaII8542',	'DTT_CaII8662',	'DTT_MgI8807',	'4000Abreak',	'HKratio']
feat_labels = ['mean radius', 'mean texture', 'mean perimeter', 'mean area','mean smoothness', 'mean compactness' ,'mean concavity','mean concave points' ,'mean symmetry', 'mean fractal dimension'
 ,'radius error' ,'texture error', 'perimeter error', 'area error'
 ,'smoothness error', 'compactness error', 'concavity error'
 ,'concave points error', 'symmetry error', 'fractal dimension error'
 ,'worst radius' ,'worst texture', 'worst perimeter', 'worst area'
 ,'worst smoothness','worst compactness' ,'worst concavity'
 ,'worst concave points', 'worst symmetry' ,'worst fractal dimension']

# Create a random forest classifier
clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)

# Train the classifier
clf.fit(X_train, y_train)

# Print the name and gini importance of each feature
for feature in zip(feat_labels, clf.feature_importances_):
    print(feature)

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import accuracy_score
sfm = SelectFromModel(clf, threshold=0.001)

# Train the selector
sfm.fit(X_train, y_train)

for feature_list_index in sfm.get_support(indices=True):
    print(feat_labels[feature_list_index])

#features =['Age', 'gender',	'diagnosis',	'diagnosis_confirm_type', 'anatom_site_general','melanocytic']
features = feat_labels
importances = rfc.feature_importances_
indices = np.argsort(importances)

plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='r', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()